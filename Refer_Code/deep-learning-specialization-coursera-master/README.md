# [Deep Learning Specialization on Coursera](https://www.coursera.org/specializations/deep-learning)
[![Build Status](https://travis-ci.org/andersy005/deep-learning-specialization-coursera.svg?branch=master)](https://travis-ci.org/andersy005/deep-learning-specialization-coursera)


**Master Deep Learning, and Break into AI**

Instructor: [Andrew Ng](http://www.andrewng.org/)

This repo contains all my work for this specialization. All the code base, quiz questions, screenshot, and images, are taken from, unless specified, [Deep Learning Specialization on Coursera](https://www.coursera.org/specializations/deep-learning).
## Goals
- Learn the foundations of Deep Learning
- Understand how to build neural networks
- Learn how to lead successful machine learning projects
- Learn about Convolutional networks, RNNs, LSTM, Adam, Dropout, BatchNorm, Xavier/He initialization, and more.
- Work on case studies from healthcare, autonomous driving, sign language reading, music generation, and natural language processing.
- Practice all these ideas in Python and in TensorFlow.


## Courses
### [Course 1: Neural Networks and Deep Learning](https://github.com/andersy005/deep-learning-specialization/tree/master/01-Neural-Networks-and-Deep-Learning)
  - [Week 1 - Introduction to deep learning
](https://github.com/andersy005/deep-learning-specialization-coursera/tree/master/01-Neural-Networks-and-Deep-Learning/week1)
    - [Quiz](https://github.com/andersy005/deep-learning-specialization-coursera/blob/master/01-Neural-Networks-and-Deep-Learning/week1/quiz1.pdf)
  - [Week 2 - Neural Networks Basics](https://github.com/andersy005/deep-learning-specialization-coursera/tree/master/01-Neural-Networks-and-Deep-Learning/week2)
    - [Quiz](https://github.com/andersy005/deep-learning-specialization-coursera/blob/master/01-Neural-Networks-and-Deep-Learning/week2/quiz.pdf)
    - [Notes 1 - Logistic Regression as a Neural Network](https://github.com/andersy005/deep-learning-specialization-coursera/blob/master/01-Neural-Networks-and-Deep-Learning/week2/01-Logistic-Regression-as-a-Neural-Network.ipynb)
    - [Notes 2 - Vectorization](https://github.com/andersy005/deep-learning-specialization-coursera/blob/master/01-Neural-Networks-and-Deep-Learning/week2/02-vectorization.ipynb)
    - [Programming Assignment 1 - Python Basics with NumPy](https://github.com/andersy005/deep-learning-specialization-coursera/blob/master/01-Neural-Networks-and-Deep-Learning/week2/Programming-Assignments/Python%2BBasics%2BWith%2BNumpy%2Bv2.ipynb)
    - [Programming Assignment 2 - Logistic Regression with a Neural Network Mindset](https://github.com/andersy005/deep-learning-specialization-coursera/blob/master/01-Neural-Networks-and-Deep-Learning/week2/Programming-Assignments/Logistic%2BRegression%2Bwith%2Ba%2BNeural%2BNetwork%2Bmindset%2Bv3.ipynb)
    
  - [Week 3 - Shallow Neural Networks](https://github.com/andersy005/deep-learning-specialization-coursera/tree/master/01-Neural-Networks-and-Deep-Learning/week3)
    - [Quiz](https://github.com/andersy005/deep-learning-specialization-coursera/blob/master/01-Neural-Networks-and-Deep-Learning/week3/quiz.pdf)
    - [Notes - Shallow neural networks](https://github.com/andersy005/deep-learning-specialization-coursera/blob/master/01-Neural-Networks-and-Deep-Learning/week3/shallow-neural-network.ipynb)
    - [Programming Assignment - Planar Data Classification with one hidden layer](https://github.com/andersy005/deep-learning-specialization-coursera/blob/master/01-Neural-Networks-and-Deep-Learning/week3/Programming%20Assignments/Planar%2Bdata%2Bclassification%2Bwith%2Bone%2Bhidden%2Blayer%2Bv2.ipynb)
      
  - [Week 4 - Deep Neural Networks](https://github.com/andersy005/deep-learning-specialization-coursera/tree/master/01-Neural-Networks-and-Deep-Learning/week3)
    - [Quiz](https://github.com/andersy005/deep-learning-specialization-coursera/blob/master/01-Neural-Networks-and-Deep-Learning/week4/quiz.pdf)
    - [Notes - Deep neural networks](https://github.com/andersy005/deep-learning-specialization-coursera/blob/master/01-Neural-Networks-and-Deep-Learning/week4/deep-neural-networks.ipynb)
    - [Programming Assignment 1 - Building your Deep Neural Network - Step by Step](https://github.com/andersy005/deep-learning-specialization-coursera/blob/master/01-Neural-Networks-and-Deep-Learning/week4/Programming%20Assignments/Building%20your%20Deep%20Neural%20Network%20-%20Step%20by%20Step/Building%2Byour%2BDeep%2BNeural%2BNetwork%2B-%2BStep%2Bby%2BStep%2Bv3.ipynb)
    
     - [Programming Assignment 2 - Deep Neural Network Application: Image Classification](https://github.com/andersy005/deep-learning-specialization-coursera/blob/master/01-Neural-Networks-and-Deep-Learning/week4/Programming%20Assignments/Deep%20Neural%20Network%20Application:%20Image%20Classification/Deep%2BNeural%2BNetwork%2B-%2BApplication%2Bv3.ipynb)
    
    
    
### [Course 2: Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization](https://github.com/andersy005/deep-learning-specialization-coursera/tree/master/02-Improving-Deep-Neural-Networks)

- [Week 1 - Practical aspects of Deep Learning](https://github.com/andersy005/deep-learning-specialization-coursera/tree/master/02-Improving-Deep-Neural-Networks/week1)

  - **Learning Objectives**

    - Recall that different types of initializations lead to different results
    - Recognize the importance of initialization in complex neural networks.
    - Recognize the difference between train/dev/test sets
    - Diagnose the bias and variance issues in your model
    - Learn when and how to use regularization methods such as dropout or L2 regularization.
    - Understand experimental issues in deep learning such as Vanishing or Exploding gradients and learn how to deal with them
    - Use gradient checking to verify the correctness of your backpropagation implementation

  - [Quiz](https://github.com/andersy005/deep-learning-specialization-coursera/blob/master/02-Improving-Deep-Neural-Networks/week1/quiz.pdf)

  - [Notes](https://github.com/andersy005/deep-learning-specialization-coursera/blob/master/02-Improving-Deep-Neural-Networks/week1/Practical-aspects-of-Deep-Learning.ipynb)

  - [Programming Assignment 1 - Initialization](https://github.com/andersy005/deep-learning-specialization-coursera/blob/master/02-Improving-Deep-Neural-Networks/week1/Programming-Assignments/Initialization/Initialization.ipynb)

  - [Programming Assignment 2 - Regularization](https://github.com/andersy005/deep-learning-specialization-coursera/blob/master/02-Improving-Deep-Neural-Networks/week1/Programming-Assignments/Regularization/Regularization.ipynb)

  - [Programming Assignment 3 - Gradient Checking](https://github.com/andersy005/deep-learning-specialization-coursera/blob/master/02-Improving-Deep-Neural-Networks/week1/Programming-Assignments/Gradient%20Checking/Gradient%2BChecking.ipynb)
  
- [Week 2 - Optimization algorithms](https://github.com/andersy005/deep-learning-specialization-coursera/tree/master/02-Improving-Deep-Neural-Networks/week2)

  - **Learning Objectives**

    - Remember different optimization methods such as (Stochastic) Gradient Descent, Momentum, RMSProp and Adam
    - Use random minibatches to accelerate the convergence and improve the optimization
    - Know the benefits of learning rate decay and apply it to your optimization
    
  - [Quiz](https://github.com/andersy005/deep-learning-specialization-coursera/blob/master/02-Improving-Deep-Neural-Networks/week2/quiz.pdf)
  - [Notes](https://github.com/andersy005/deep-learning-specialization-coursera/blob/master/02-Improving-Deep-Neural-Networks/week2/optimization-algoritihms.ipynb)
  - [Programming Assignment - Optimization Methods](https://github.com/andersy005/deep-learning-specialization-coursera/blob/master/02-Improving-Deep-Neural-Networks/week2/Programming-Assignments/Optimization%2Bmethods.ipynb)

## Try notebooks in the cloud

To try out example notebooks interactively in your web browser, just click on the binder link:

[![Binder](https://i.imgur.com/xzKbKkP.png)](http://binder.pangeo.io/v2/gh/andersy005/deep-learning-specialization-coursera/master)


## Contributing

Contributions are welcome! For bug reports or requests please submit an issue.